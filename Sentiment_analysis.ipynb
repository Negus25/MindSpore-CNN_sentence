{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "178af0c1-e280-438f-97e6-6e95d0f5ad02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MindSpore version:  2.0.0rc1.dev20230507\n",
      "The result of multiplication calculation is correct, MindSpore has been installed on platform [GPU] successfully!\n"
     ]
    }
   ],
   "source": [
    "import mindspore;mindspore.run_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e68ba1-0991-41b4-be00-a4b526e356da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://repo.huaweicloud.com/repository/pypi/simple\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.8/site-packages (4.61.2)\n",
      "Requirement already satisfied: requests in /root/miniconda3/lib/python3.8/site-packages (2.25.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/lib/python3.8/site-packages (from requests) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /root/miniconda3/lib/python3.8/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /root/miniconda3/lib/python3.8/site-packages (from requests) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /root/miniconda3/lib/python3.8/site-packages (from requests) (2.10)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd25f784-0770-4b3e-9ccd-1b2c99584b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import tempfile\n",
    "from tqdm import tqdm\n",
    "from typing import IO\n",
    "from pathlib import Path\n",
    "\n",
    "# Set the storage path to `home_path/.mindspore_examples`.\n",
    "cache_dir ='./dataset' \n",
    "#Path.home() / '.mindspore_examples'\n",
    "\n",
    "def http_get(url: str, temp_file: IO):\n",
    "    \"\"\"Download data by using the requests library and visualize the process by using the tqdm library.\"\"\"\n",
    "    req = requests.get(url, stream=True)\n",
    "    content_length = req.headers.get('Content-Length')\n",
    "    total = int(content_length) if content_length is not None else None\n",
    "    progress = tqdm(unit='B', total=total)\n",
    "    for chunk in req.iter_content(chunk_size=1024):\n",
    "        if chunk:\n",
    "            progress.update(len(chunk))\n",
    "            temp_file.write(chunk)\n",
    "    progress.close()\n",
    "\n",
    "def download(file_name: str, url: str):\n",
    "    \"\"\"Download data and save it with the specified name.\"\"\"\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    cache_path = os.path.join(cache_dir, file_name)\n",
    "    cache_exist = os.path.exists(cache_path)\n",
    "    if not cache_exist:\n",
    "        with tempfile.NamedTemporaryFile() as temp_file:\n",
    "            http_get(url, temp_file)\n",
    "            temp_file.flush()\n",
    "            temp_file.seek(0)\n",
    "            with open(cache_path, 'wb') as cache_file:\n",
    "                shutil.copyfileobj(temp_file, cache_file)\n",
    "    return cache_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce74a37f-b0fc-40e9-8720-9364b3942010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./dataset/aclImdb_v1.tar.gz'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_path = download('aclImdb_v1.tar.gz', 'https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/aclImdb_v1.tar.gz')\n",
    "imdb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1af480a8-30d4-4b2a-92b4-ab273a312732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import six\n",
    "import string\n",
    "import tarfile\n",
    "\n",
    "class IMDBData():\n",
    "    \"\"\"IMDB dataset loader.\n",
    "\n",
    "    Load the IMDB dataset and process it as a Python iteration object.\n",
    "\n",
    "    \"\"\"\n",
    "    label_map = {\n",
    "        \"pos\": 1,\n",
    "        \"neg\": 0\n",
    "    }\n",
    "    def __init__(self, path, mode=\"train\"):\n",
    "        self.mode = mode\n",
    "        self.path = path\n",
    "        self.docs, self.labels = [], []\n",
    "\n",
    "        self._load(\"pos\")\n",
    "        self._load(\"neg\")\n",
    "\n",
    "    def _load(self, label):\n",
    "        pattern = re.compile(r\"aclImdb/{}/{}/.*\\.txt$\".format(self.mode, label))\n",
    "        # Load data to the memory.\n",
    "        with tarfile.open(self.path) as tarf:\n",
    "            tf = tarf.next()\n",
    "            while tf is not None:\n",
    "                if bool(pattern.match(tf.name)):\n",
    "                    # Segment text, remove punctuations and special characters, and convert text to lowercase.\n",
    "                    self.docs.append(str(tarf.extractfile(tf).read().rstrip(six.b(\"\\n\\r\"))\n",
    "                                         .translate(None, six.b(string.punctuation)).lower()).split())\n",
    "                    self.labels.append([self.label_map[label]])\n",
    "                tf = tarf.next()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.docs[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c079ad08-e173-4864-bc11-929beb3bd079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train = IMDBData(imdb_path, 'train')\n",
    "len(imdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0eb86f5-0b87-419d-830d-cefcd464a272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test = IMDBData(imdb_path, 'test')\n",
    "len(imdb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25504c1-c7f0-4463-87cf-a21a874873cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"b'zentropa\",\n",
       "  'is',\n",
       "  'the',\n",
       "  'most',\n",
       "  'original',\n",
       "  'movie',\n",
       "  'ive',\n",
       "  'seen',\n",
       "  'in',\n",
       "  'years',\n",
       "  'if',\n",
       "  'you',\n",
       "  'like',\n",
       "  'unique',\n",
       "  'thrillers',\n",
       "  'that',\n",
       "  'are',\n",
       "  'influenced',\n",
       "  'by',\n",
       "  'film',\n",
       "  'noir',\n",
       "  'then',\n",
       "  'this',\n",
       "  'is',\n",
       "  'just',\n",
       "  'the',\n",
       "  'right',\n",
       "  'cure',\n",
       "  'for',\n",
       "  'all',\n",
       "  'of',\n",
       "  'those',\n",
       "  'hollywood',\n",
       "  'summer',\n",
       "  'blockbusters',\n",
       "  'clogging',\n",
       "  'the',\n",
       "  'theaters',\n",
       "  'these',\n",
       "  'days',\n",
       "  'von',\n",
       "  'triers',\n",
       "  'followups',\n",
       "  'like',\n",
       "  'breaking',\n",
       "  'the',\n",
       "  'waves',\n",
       "  'have',\n",
       "  'gotten',\n",
       "  'more',\n",
       "  'acclaim',\n",
       "  'but',\n",
       "  'this',\n",
       "  'is',\n",
       "  'really',\n",
       "  'his',\n",
       "  'best',\n",
       "  'work',\n",
       "  'it',\n",
       "  'is',\n",
       "  'flashy',\n",
       "  'without',\n",
       "  'being',\n",
       "  'distracting',\n",
       "  'and',\n",
       "  'offers',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  'combination',\n",
       "  'of',\n",
       "  'suspense',\n",
       "  'and',\n",
       "  'dark',\n",
       "  'humor',\n",
       "  'its',\n",
       "  'too',\n",
       "  'bad',\n",
       "  'he',\n",
       "  'decided',\n",
       "  'handheld',\n",
       "  'cameras',\n",
       "  'were',\n",
       "  'the',\n",
       "  'wave',\n",
       "  'of',\n",
       "  'the',\n",
       "  'future',\n",
       "  'its',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'say',\n",
       "  'who',\n",
       "  'talked',\n",
       "  'him',\n",
       "  'away',\n",
       "  'from',\n",
       "  'the',\n",
       "  'style',\n",
       "  'he',\n",
       "  'exhibits',\n",
       "  'here',\n",
       "  'but',\n",
       "  'its',\n",
       "  'everyones',\n",
       "  'loss',\n",
       "  'that',\n",
       "  'he',\n",
       "  'went',\n",
       "  'into',\n",
       "  'his',\n",
       "  'heavily',\n",
       "  'theoretical',\n",
       "  'dogma',\n",
       "  'direction',\n",
       "  \"instead'\"],\n",
       " [1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.__getitem__(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7e00c2c-c9ab-4b03-a61a-dd0ac9a6eae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([\"b'piece\",\n",
       "  'of',\n",
       "  'subtle',\n",
       "  'art',\n",
       "  'maybe',\n",
       "  'a',\n",
       "  'masterpiece',\n",
       "  'doubtlessly',\n",
       "  'a',\n",
       "  'special',\n",
       "  'story',\n",
       "  'about',\n",
       "  'the',\n",
       "  'ambiguity',\n",
       "  'of',\n",
       "  'existence',\n",
       "  'tale',\n",
       "  'in',\n",
       "  'kafka',\n",
       "  'style',\n",
       "  'about',\n",
       "  'impossibility',\n",
       "  'of',\n",
       "  'victory',\n",
       "  'or',\n",
       "  'surviving',\n",
       "  'in',\n",
       "  'a',\n",
       "  'perpetual',\n",
       "  'strange',\n",
       "  'world',\n",
       "  'the',\n",
       "  'life',\n",
       "  'is',\n",
       "  'in',\n",
       "  'this',\n",
       "  'film',\n",
       "  'only',\n",
       "  'exercise',\n",
       "  'of',\n",
       "  'adaptation',\n",
       "  'lesson',\n",
       "  'about',\n",
       "  'limits',\n",
       "  'and',\n",
       "  'original',\n",
       "  'sin',\n",
       "  'about',\n",
       "  'the',\n",
       "  'frailty',\n",
       "  'of',\n",
       "  'innocence',\n",
       "  'and',\n",
       "  'error',\n",
       "  'of',\n",
       "  'his',\n",
       "  'waysbr',\n",
       "  'br',\n",
       "  'leopold',\n",
       "  'kessle',\n",
       "  'is',\n",
       "  'another',\n",
       "  'joseph',\n",
       "  'k',\n",
       "  'images',\n",
       "  'of',\n",
       "  'trial',\n",
       "  'and',\n",
       "  'same',\n",
       "  'ambiguous',\n",
       "  'woman',\n",
       "  'and',\n",
       "  'europa',\n",
       "  'is',\n",
       "  'symbol',\n",
       "  'of',\n",
       "  'basic',\n",
       "  'crisis',\n",
       "  'who',\n",
       "  'has',\n",
       "  'many',\n",
       "  'aspects',\n",
       "  'like',\n",
       "  'chimeric',\n",
       "  'wars',\n",
       "  'or',\n",
       "  'unavailing',\n",
       "  'search',\n",
       "  'of',\n",
       "  'truthessencegolden',\n",
       "  'agebr',\n",
       "  'br',\n",
       "  'methaphor',\n",
       "  'or',\n",
       "  'parable',\n",
       "  'the',\n",
       "  'movie',\n",
       "  'is',\n",
       "  'history',\n",
       "  'of',\n",
       "  'disappointeds',\n",
       "  'evolution',\n",
       "  'war',\n",
       "  'peace',\n",
       "  'business',\n",
       "  'or',\n",
       "  'lie',\n",
       "  'are',\n",
       "  'only',\n",
       "  'details',\n",
       "  'of',\n",
       "  'gelatintime',\n",
       "  'hypocrisy',\n",
       "  'is',\n",
       "  'a',\n",
       "  'mask',\n",
       "  'love',\n",
       "  'a',\n",
       "  'convention',\n",
       "  'the',\n",
       "  'sacrifice',\n",
       "  'only',\n",
       "  'method',\n",
       "  'to',\n",
       "  'hope',\n",
       "  'understanding',\n",
       "  'a',\n",
       "  'painful',\n",
       "  \"reality'\"],\n",
       " [1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train.__getitem__(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4804043e-1e49-4eb7-974a-2b8d99fca0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.dataset as ds\n",
    "\n",
    "def load_imdb(imdb_path):\n",
    "    imdb_train = ds.GeneratorDataset(IMDBData(imdb_path, \"train\"), column_names=[\"text\", \"label\"], shuffle=False)\n",
    "    imdb_test = ds.GeneratorDataset(IMDBData(imdb_path, \"test\"), column_names=[\"text\", \"label\"], shuffle=False)\n",
    "    return imdb_train, imdb_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b65bf91-fbcb-4186-8fe2-d74ab0e2e8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mindspore.dataset.engine.datasets_user_defined.GeneratorDataset at 0x7ff419189040>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train, imdb_test = load_imdb(imdb_path)\n",
    "imdb_train\n",
    "imdb_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be133922-71a3-49b7-922e-36f9188e889b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f4e4a0-49c5-4a37-93b7-878eefa9c427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tensor(shape=[121], dtype=String, value= [\"b'zentropa\", 'has', 'much', 'in', 'common', 'with', 'the', 'third',\n",
       "  'man', 'another', 'noirlike', 'film', 'set', 'among', 'the', 'rubble',\n",
       "  'of', 'postwar', 'europe', 'like', 'ttm', 'there', 'is', 'much',\n",
       "  'inventive', 'camera', 'work', 'there', 'is', 'an', 'innocent',\n",
       "  'american', 'who', 'gets', 'emotionally', 'involved', 'with', 'a',\n",
       "  'woman', 'he', 'doesnt', 'really', 'understand', 'and', 'whose',\n",
       "  'naivety', 'is', 'all', 'the', 'more', 'striking', 'in', 'contrast',\n",
       "  'with', 'the', 'nativesbr', 'br', 'but', 'id', 'have', 'to', 'say',\n",
       "  'that', 'the', 'third', 'man', 'has', 'a', 'more', 'wellcrafted',\n",
       "  'storyline', 'zentropa', 'is', 'a', 'bit', 'disjointed', 'in', 'this',\n",
       "  'respect', 'perhaps', 'this', 'is', 'intentional', 'it', 'is',\n",
       "  'presented', 'as', 'a', 'dreamnightmare', 'and', 'making', 'it', 'too',\n",
       "  'coherent', 'would', 'spoil', 'the', 'effect', 'br', 'br', 'this',\n",
       "  'movie', 'is', 'unrelentingly', 'grimnoir', 'in', 'more', 'than', 'one',\n",
       "  'sense', 'one', 'never', 'sees', 'the', 'sun', 'shine', 'grim', 'but',\n",
       "  'intriguing', 'and', \"frightening'\"]),\n",
       " Tensor(shape=[1], dtype=Int64, value= [1])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= next(imdb_train.create_tuple_iterator())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b9d167e-7247-4ad0-af53-e295ee55440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "def load_glove(glove_path):\n",
    "    glove_100d_path = os.path.join(cache_dir, 'glove.6B.100d.txt')\n",
    "    if not os.path.exists(glove_100d_path):\n",
    "        glove_zip = zipfile.ZipFile(glove_path)\n",
    "        glove_zip.extractall(cache_dir)\n",
    "\n",
    "    embeddings = []\n",
    "    tokens = []\n",
    "    with open(glove_100d_path, encoding='utf-8') as gf:\n",
    "        for glove in gf:\n",
    "            word, embedding = glove.split(maxsplit=1)\n",
    "            tokens.append(word)\n",
    "            embeddings.append(np.fromstring(embedding, dtype=np.float32, sep=' '))\n",
    "    # Add the embeddings corresponding to the special placeholders <unk> and <pad>.\n",
    "    embeddings.append(np.random.rand(100))\n",
    "    embeddings.append(np.zeros((100,), np.float32))\n",
    "\n",
    "    vocab = ds.text.Vocab.from_list(tokens, special_tokens=[\"<unk>\", \"<pad>\"], special_first=False)\n",
    "    embeddings = np.array(embeddings).astype(np.float32)\n",
    "    return vocab, embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a0b93cc-385e-419b-a209-745245eecfec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400002"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_path = download('glove.6B.zip', 'https://mindspore-website.obs.myhuaweicloud.com/notebook/datasets/glove.6B.zip')\n",
    "vocab, embeddings = load_glove(glove_path)\n",
    "len(vocab.vocab())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf1d8d3d-47ed-4f25-961c-392ddda645ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400002"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab.vocab())\n",
    "#len(embeddings.embeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c57fa7c-aa96-4e8d-b2b7-c6c5c173e1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = vocab.tokens_to_ids('the')\n",
    "embedding = embeddings[idx]\n",
    "idx, embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26bbe727-9a30-4b8d-b254-576d796ee5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400001,\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = vocab.tokens_to_ids('<pad>')\n",
    "embedding = embeddings[idx]\n",
    "idx, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "040138ea-8aac-48ed-a026-fe8f8bc98510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore as ms\n",
    "\n",
    "lookup_op = ds.text.Lookup(vocab, unknown_token='<unk>')\n",
    "pad_op = ds.transforms.PadEnd([500], pad_value=vocab.tokens_to_ids('<pad>'))\n",
    "type_cast_op = ds.transforms.TypeCast(ms.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a201a596-5841-44be-b045-331b66c4e773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "Text: [\"b'zentropa\" 'has' 'much' 'in' 'common' 'with' 'the' 'third' 'man'\n",
      " 'another' 'noirlike' 'film' 'set' 'among' 'the' 'rubble' 'of' 'postwar'\n",
      " 'europe' 'like' 'ttm' 'there' 'is' 'much' 'inventive' 'camera' 'work'\n",
      " 'there' 'is' 'an' 'innocent' 'american' 'who' 'gets' 'emotionally'\n",
      " 'involved' 'with' 'a' 'woman' 'he' 'doesnt' 'really' 'understand' 'and'\n",
      " 'whose' 'naivety' 'is' 'all' 'the' 'more' 'striking' 'in' 'contrast'\n",
      " 'with' 'the' 'nativesbr' 'br' 'but' 'id' 'have' 'to' 'say' 'that' 'the'\n",
      " 'third' 'man' 'has' 'a' 'more' 'wellcrafted' 'storyline' 'zentropa' 'is'\n",
      " 'a' 'bit' 'disjointed' 'in' 'this' 'respect' 'perhaps' 'this' 'is'\n",
      " 'intentional' 'it' 'is' 'presented' 'as' 'a' 'dreamnightmare' 'and'\n",
      " 'making' 'it' 'too' 'coherent' 'would' 'spoil' 'the' 'effect' 'br' 'br'\n",
      " 'this' 'movie' 'is' 'unrelentingly' 'grimnoir' 'in' 'more' 'than' 'one'\n",
      " 'sense' 'one' 'never' 'sees' 'the' 'sun' 'shine' 'grim' 'but'\n",
      " 'intriguing' 'and' \"frightening'\"]\n",
      "Label: [1]\n",
      "Sample 1:\n",
      "Text: [\"b'zentropa\" 'is' 'the' 'most' 'original' 'movie' 'ive' 'seen' 'in'\n",
      " 'years' 'if' 'you' 'like' 'unique' 'thrillers' 'that' 'are' 'influenced'\n",
      " 'by' 'film' 'noir' 'then' 'this' 'is' 'just' 'the' 'right' 'cure' 'for'\n",
      " 'all' 'of' 'those' 'hollywood' 'summer' 'blockbusters' 'clogging' 'the'\n",
      " 'theaters' 'these' 'days' 'von' 'triers' 'followups' 'like' 'breaking'\n",
      " 'the' 'waves' 'have' 'gotten' 'more' 'acclaim' 'but' 'this' 'is' 'really'\n",
      " 'his' 'best' 'work' 'it' 'is' 'flashy' 'without' 'being' 'distracting'\n",
      " 'and' 'offers' 'the' 'perfect' 'combination' 'of' 'suspense' 'and' 'dark'\n",
      " 'humor' 'its' 'too' 'bad' 'he' 'decided' 'handheld' 'cameras' 'were'\n",
      " 'the' 'wave' 'of' 'the' 'future' 'its' 'hard' 'to' 'say' 'who' 'talked'\n",
      " 'him' 'away' 'from' 'the' 'style' 'he' 'exhibits' 'here' 'but' 'its'\n",
      " 'everyones' 'loss' 'that' 'he' 'went' 'into' 'his' 'heavily'\n",
      " 'theoretical' 'dogma' 'direction' \"instead'\"]\n",
      "Label: [1]\n",
      "Sample 2:\n",
      "Text: [\"b'lars\" 'von' 'trier' 'is' 'never' 'backward' 'in' 'trying' 'out' 'new'\n",
      " 'techniques' 'some' 'of' 'them' 'are' 'very' 'original' 'while' 'others'\n",
      " 'are' 'best' 'forgottenbr' 'br' 'he' 'depicts' 'postwar' 'germany' 'as'\n",
      " 'a' 'nightmarish' 'train' 'journey' 'with' 'so' 'many' 'cities' 'lying'\n",
      " 'in' 'ruins' 'leo' 'kessler' 'a' 'young' 'american' 'of' 'german'\n",
      " 'descent' 'feels' 'obliged' 'to' 'help' 'in' 'their' 'restoration' 'it'\n",
      " 'is' 'not' 'a' 'simple' 'task' 'as' 'he' 'quickly' 'finds' 'outbr' 'br'\n",
      " 'his' 'uncle' 'finds' 'him' 'a' 'job' 'as' 'a' 'night' 'conductor' 'on'\n",
      " 'the' 'zentropa' 'railway' 'line' 'his' 'job' 'is' 'to' 'attend' 'to'\n",
      " 'the' 'needs' 'of' 'the' 'passengers' 'when' 'the' 'shoes' 'are'\n",
      " 'polished' 'a' 'chalk' 'mark' 'is' 'made' 'on' 'the' 'soles' 'a'\n",
      " 'terrible' 'argument' 'ensues' 'when' 'a' 'passengers' 'shoes' 'are'\n",
      " 'not' 'chalked' 'despite' 'the' 'fact' 'they' 'have' 'been' 'polished'\n",
      " 'there' 'are' 'many' 'allusions' 'to' 'the' 'german' 'fanaticism' 'of'\n",
      " 'adherence' 'to' 'such' 'stupid' 'detailsbr' 'br' 'the' 'railway'\n",
      " 'journey' 'is' 'like' 'an' 'allegory' 'representing' 'mans' 'procession'\n",
      " 'through' 'life' 'with' 'all' 'its' 'trials' 'and' 'tribulations' 'in'\n",
      " 'one' 'sequence' 'leo' 'dashes' 'through' 'the' 'back' 'carriages' 'to'\n",
      " 'discover' 'them' 'filled' 'with' 'halfstarved' 'bodies' 'appearing' 'to'\n",
      " 'have' 'just' 'escaped' 'from' 'auschwitz' 'these' 'images' 'horrible'\n",
      " 'as' 'they' 'are' 'are' 'fleeting' 'as' 'in' 'a' 'dream' 'each' 'with'\n",
      " 'its' 'own' 'terrible' 'impact' 'yet' 'unconnectedbr' 'br' 'at' 'a'\n",
      " 'station' 'called' 'urmitz' 'leo' 'jumps' 'from' 'the' 'train' 'with' 'a'\n",
      " 'parceled' 'bomb' 'in' 'view' 'of' 'many' 'bystanders' 'he' 'connects'\n",
      " 'the' 'bomb' 'to' 'the' 'underside' 'of' 'a' 'carriage' 'he' 'returns'\n",
      " 'to' 'his' 'cabin' 'and' 'makes' 'a' 'connection' 'to' 'a' 'time' 'clock'\n",
      " 'later' 'he' 'jumps' 'from' 'the' 'train' 'at' 'high' 'speed' 'and'\n",
      " 'lies' 'in' 'the' 'cool' 'grass' 'on' 'a' 'river' 'bank' 'looking' 'at'\n",
      " 'the' 'stars' 'above' 'he' 'decides' 'that' 'his' 'job' 'is' 'to' 'build'\n",
      " 'and' 'not' 'destroy' 'subsequently' 'as' 'he' 'sees' 'the' 'train'\n",
      " 'approaching' 'a' 'giant' 'bridge' 'he' 'runs' 'at' 'breakneck' 'speed'\n",
      " 'to' 'board' 'the' 'train' 'and' 'stop' 'the' 'clock' 'if' 'you' 'care'\n",
      " 'to' 'analyse' 'the' 'situation' 'it' 'is' 'a' 'completely' 'impossible'\n",
      " 'task' 'quite' 'ridiculous' 'in' 'fact' 'it' 'could' 'only' 'happen' 'in'\n",
      " 'a' 'dreambr' 'br' 'its' 'strange' 'how' 'one' 'remembers' 'little'\n",
      " 'details' 'such' 'as' 'a' 'row' 'of' 'cups' 'hanging' 'on' 'hooks' 'and'\n",
      " 'rattling' 'away' 'with' 'the' 'swaying' 'of' 'the' 'trainbr' 'br'\n",
      " 'despite' 'the' 'fact' 'that' 'this' 'film' 'is' 'widely' 'acclaimed' 'i'\n",
      " 'prefer' 'lars' 'von' 'triers' 'later' 'films' 'breaking' 'the' 'waves'\n",
      " 'and' 'the' 'idiots' 'the' 'bomb' 'scene' 'described' 'above' 'really'\n",
      " 'put' 'me' 'off' 'perhaps' 'im' 'a' \"realist'\"]\n",
      "Label: [1]\n",
      "Sample 3:\n",
      "Text: [\"b'contains\" 'spoilers' 'due' 'to' 'me' 'having' 'to' 'describe' 'some'\n",
      " 'film' 'techniques' 'so' 'read' 'at' 'your' 'own' 'riskbr' 'br' 'i'\n",
      " 'loved' 'this' 'film' 'the' 'use' 'of' 'tinting' 'in' 'some' 'of' 'the'\n",
      " 'scenes' 'makes' 'it' 'seem' 'like' 'an' 'old' 'photograph' 'come' 'to'\n",
      " 'life' 'i' 'also' 'enjoyed' 'the' 'projection' 'of' 'people' 'on' 'a'\n",
      " 'back' 'screen' 'for' 'instance' 'in' 'one' 'scene' 'leopold' 'calls'\n",
      " 'his' 'wife' 'and' 'she' 'is' 'projected' 'behind' 'him' 'rather' 'than'\n",
      " 'in' 'a' 'typical' 'split' 'screen' 'her' 'face' 'is' 'huge' 'in' 'the'\n",
      " 'back' 'and' 'leos' 'is' 'in' 'the' 'foregroundbr' 'br' 'one' 'of' 'the'\n",
      " 'best' 'uses' 'of' 'this' 'is' 'when' 'the' 'young' 'boys' 'kill' 'the'\n",
      " 'ravensteins' 'on' 'the' 'train' 'a' 'scene' 'shot' 'in' 'an' 'almost'\n",
      " 'political' 'poster' 'style' 'with' 'facial' 'close' 'ups' 'it'\n",
      " 'reminded' 'me' 'of' 'battleship' 'potemkin' 'that' 'intense' 'constant'\n",
      " 'style' 'coupled' 'with' 'the' 'spray' 'of' 'red' 'to' 'convey' 'tons'\n",
      " 'of' 'horror' 'without' 'much' 'gore' 'same' 'with' 'the' 'scene' 'when'\n",
      " 'katharina' 'finds' 'her' 'father' 'dead' 'in' 'the' 'bathtubyou' 'can'\n",
      " 'only' 'see' 'the' 'red' 'water' 'on' 'the' 'side' 'it' 'is' 'one' 'of'\n",
      " 'the' 'things' 'i' 'love' 'about' 'von' 'trier' 'his' 'understatement'\n",
      " 'of' 'horror' 'which' 'ends' 'up' 'making' 'it' 'all' 'the' 'more'\n",
      " 'creepybr' 'br' 'the' 'use' 'of' 'text' 'in' 'the' 'film' 'was' 'unique'\n",
      " 'like' 'when' 'leos' 'character' 'is' 'pushed' 'by' 'the' 'word'\n",
      " 'werewolf' 'i' 'have' 'never' 'seen' 'anything' 'like' 'that' 'in' 'a'\n",
      " 'filmbr' 'br' 'the' 'use' 'of' 'black' 'comedy' 'in' 'this' 'film' 'was'\n",
      " 'well' 'done' 'ernsthugo' 'j\\\\xc3\\\\xa4reg\\\\xc3\\\\xa5rd' 'is' 'great' 'as'\n",
      " 'leos' 'uncle' 'it' 'brings' 'up' 'the' 'snickers' 'i' 'got' 'from' 'his'\n",
      " 'role' 'in' 'the' 'kingdom' 'riget' 'this' 'humor' 'makes' 'the'\n",
      " 'plotline' 'of' 'absurd' 'anal' 'retentiveness' 'of' 'train' 'conductors'\n",
      " 'against' 'the' 'terrible' 'backdrop' 'of' 'ww2' 'and' 'all' 'the'\n",
      " 'chaos' 'easier' 'to' 'take' 'it' 'reminds' 'me' 'of' 'riget' 'in' 'the'\n",
      " 'way' 'the' 'hospital' 'administrator' 'is' 'trying' 'to' 'maintain' 'a'\n",
      " 'normalcy' 'at' 'the' 'end' 'of' 'part' 'one' 'when' 'everything' 'is'\n",
      " 'going' 'crazy' 'it' 'shows' 'that' 'some' 'people' 'are' 'truly'\n",
      " 'oblivious' 'to' 'the' 'awful' 'things' 'happening' 'around' 'them' 'yet'\n",
      " 'some' 'people' 'like' 'leo' 'are' 'tuned' 'in' 'but' 'do' 'nothing'\n",
      " 'positive' 'about' 'itbr' 'br' 'the' 'voice' 'over' 'done' 'expertly'\n",
      " 'well' 'by' 'max' 'von' 'sydow' 'is' 'amusing' 'too' 'it' 'draws' 'you'\n",
      " 'into' 'the' 'story' 'and' 'makes' 'you' 'jump' 'into' 'leos' 'head'\n",
      " 'which' 'at' 'times' 'is' 'a' 'scary' 'place' 'to' 'bebr' 'br' 'the'\n",
      " 'movie' 'brings' 'up' 'the' 'point' 'that' 'one' 'is' 'a' 'coward' 'if'\n",
      " 'they' 'dont' 'choose' 'a' 'side' 'i' 'see' 'the' 'same' 'idea' 'used'\n",
      " 'in' 'dancer' 'in' 'the' 'dark' 'where' 'bjorks' 'character' 'doesnt'\n",
      " 'speak' 'up' 'for' 'herself' 'and' 'ends' 'up' 'being' 'her' 'own'\n",
      " 'destruction' 'actually' 'at' 'one' 'time' 'von' 'trier' 'seemed'\n",
      " 'antiwoman' 'to' 'me' 'by' 'making' 'breaking' 'the' 'waves' 'and'\n",
      " 'dancer' 'but' 'now' 'i' 'know' 'his' 'male' 'characters' 'dont' 'fare'\n",
      " 'well' 'either' 'i' 'found' 'myself' 'at' 'the' 'same' 'place' 'during'\n",
      " 'the' 'end' 'of' 'dancer' 'when' 'you' 'seriously' 'want' 'the' 'main'\n",
      " 'character' 'to' 'rethink' 'their' 'actions' 'but' 'of' 'course' 'they'\n",
      " 'never' \"do'\"]\n",
      "Label: [1]\n",
      "Sample 4:\n",
      "Text: [\"b'that\" 'was' 'the' 'first' 'thing' 'that' 'sprang' 'to' 'mind' 'as' 'i'\n",
      " 'watched' 'the' 'closing' 'credits' 'to' 'europa' 'make' 'there' 'was'\n",
      " 'across' 'the' 'screen' 'never' 'in' 'my' 'entire' 'life' 'have' 'i'\n",
      " 'seen' 'a' 'film' 'of' 'such' 'technical' 'genius' 'the' 'visuals' 'of'\n",
      " 'europa' 'are' 'so' 'impressive' 'that' 'any' 'film' 'i' 'watch' 'in'\n",
      " 'its' 'wake' 'will' 'only' 'pale' 'in' 'comparison' 'forget' 'your'\n",
      " 'michael' 'bay' 'ridley' 'scott' 'slick' 'hollywood' 'cinematography'\n",
      " 'europa' 'has' 'more' 'ethereal' 'beauty' 'than' 'anything' 'those' 'two'\n",
      " 'could' 'conjure' 'up' 'in' 'a' 'million' 'years' 'now' 'id' 'be' 'the'\n",
      " 'first' 'to' 'hail' 'lars' 'von' 'trier' 'a' 'genius' 'just' 'off' 'the'\n",
      " 'back' 'of' 'his' 'films' 'breaking' 'the' 'waves' 'and' 'dancer' 'in'\n",
      " 'the' 'dark' 'but' 'this' 'is' 'stupid' 'the' 'fact' 'that' 'europa'\n",
      " 'has' 'gone' 'unnoticed' 'by' 'film' 'experts' 'for' 'so' 'long' 'is' 'a'\n",
      " 'crime' 'against' 'cinema' 'whilst' 'overrated' 'rubbish' 'like'\n",
      " 'crouching' 'tiger' 'hidden' 'dragon' 'and' 'life' 'is' 'beautiful'\n",
      " 'clean' 'up' 'at' 'the' 'academy' 'awards' 'but' 'what' 'do' 'the' 'know'\n",
      " 'europa' 'has' 'been' 'hidden' 'away' 'absent' 'form' 'video' 'stores'\n",
      " 'and' 'until' 'recently' 'any' 'british' 'tv' 'channels' 'br' 'br' 'the'\n",
      " 'visuals' 'in' 'europa' 'are' 'not' 'mtv' 'gloss' 'its' 'not' 'a' 'case'\n",
      " 'of' 'style' 'over' 'substance' 'its' 'more' 'a' 'case' 'of' 'substance'\n",
      " 'dictating' 'style' 'much' 'like' 'his' 'first' 'film' 'the' 'element'\n",
      " 'of' 'crime' 'von' 'trier' 'uses' 'the' 'perspective' 'of' 'the' 'main'\n",
      " 'character' 'to' 'draw' 'us' 'into' 'his' 'world' 'and' 'much' 'like'\n",
      " 'element' 'the' 'film' 'begins' 'with' 'the' 'main' 'character' 'or' 'in'\n",
      " 'the' 'case' 'of' 'europa' 'we' 'the' 'audience' 'being' 'hypnotized'\n",
      " 'as' 'we' 'move' 'down' 'the' 'tracks' 'the' 'voice' 'of' 'the'\n",
      " 'narrator' 'max' 'von' 'sydow' 'counts' 'us' 'down' 'into' 'a' 'deep'\n",
      " 'sleep' 'until' 'we' 'awake' 'in' 'europa' 'this' 'allows' 'von' 'trier'\n",
      " 'and' 'his' 'three' 'cinematographers' 'to' 'pay' 'with' 'the'\n",
      " 'conventions' 'of' 'time' 'and' 'imagery' 'there' 'are' 'many' 'scenes'\n",
      " 'in' 'europa' 'when' 'a' 'character' 'in' 'the' 'background' 'who' 'is'\n",
      " 'in' 'black' 'and' 'white' 'will' 'interact' 'with' 'a' 'person' 'in'\n",
      " 'the' 'foreground' 'who' 'will' 'be' 'colour' 'von' 'trier' 'is' 'trying'\n",
      " 'to' 'show' 'us' 'how' 'much' 'precedence' 'the' 'coloured' 'item' 'or'\n",
      " 'person' 'has' 'over' 'the' 'plot' 'for' 'instance' 'its' 'no' 'surprise'\n",
      " 'that' 'the' 'first' 'shot' 'of' 'leopold' 'kessler' 'jeanmarc' 'barr'\n",
      " 'is' 'in' 'colour' 'since' 'he' 'is' 'the' 'only' 'character' 'whos'\n",
      " 'actions' 'have' 'superiority' 'over' 'the' 'film' 'br' 'br' 'the'\n",
      " 'performances' 'are' 'good' 'they' 'may' 'not' 'be' 'on' 'par' 'with'\n",
      " 'performances' 'in' 'later' 'von' 'trier' 'films' 'but' 'thats' 'just'\n",
      " 'because' 'the' 'images' 'are' 'sometimes' 'so' 'distracting' 'that'\n",
      " 'you' 'dont' 'really' 'pick' 'up' 'on' 'them' 'the' 'first' 'time'\n",
      " 'round' 'but' 'i' 'would' 'like' 'to' 'point' 'out' 'the' 'fantastic'\n",
      " 'performance' 'of' 'jeanmarc' 'barr' 'in' 'the' 'lead' 'role' 'whose'\n",
      " 'blind' 'idealism' 'is' 'slowly' 'warn' 'down' 'by' 'the' 'two'\n",
      " 'opposing' 'sides' 'until' 'he' 'erupts' 'in' 'the' 'films' 'final' 'act'\n",
      " 'again' 'muck' 'like' 'the' 'element' 'of' 'crime' 'the' 'film' 'ends'\n",
      " 'with' 'our' 'hero' 'unable' 'to' 'wake' 'up' 'from' 'his' 'nightmare'\n",
      " 'state' 'left' 'in' 'this' 'terrible' 'place' 'with' 'only' 'the'\n",
      " 'continuing' 'narration' 'of' 'von' 'sydow' 'to' 'seal' 'his' 'fate'\n",
      " 'europa' 'is' 'a' 'tremendous' 'film' 'and' 'i' 'cant' 'help' 'thinking'\n",
      " 'what' 'a' 'shame' 'that' 'von' 'trier' 'has' 'abandoned' 'this' 'way'\n",
      " 'of' 'filming' 'since' 'he' 'was' 'clearly' 'one' 'of' 'the' 'most'\n",
      " 'talented' 'visual' 'directors' 'working' 'at' 'that' 'time' 'europa'\n",
      " 'much' 'like' 'the' 'rest' 'of' 'his' 'cinematic' 'cannon' 'is' 'filled'\n",
      " 'with' 'a' 'wealth' 'of' 'iconic' 'scenes' 'his' 'dedication' 'to'\n",
      " 'composition' 'and' 'miseenscene' 'is' 'unrivalled' 'not' 'to' 'mention'\n",
      " 'his' 'use' 'of' 'sound' 'and' 'production' 'design' 'but' 'since' 'his'\n",
      " 'nofrills' 'melodramas' 'turned' 'out' 'to' 'be' 'breaking' 'the' 'waves'\n",
      " 'and' 'dancer' 'in' 'the' 'dark' 'then' 'who' 'can' 'argue' 'but' 'it'\n",
      " 'does' 'seems' 'like' 'a' 'waste' 'of' 'an' 'imaginative' 'talent'\n",
      " \"1010'\"]\n",
      "Label: [1]\n",
      "Sample 5:\n",
      "Text: [\"b'i\" 'had' 'started' 'to' 'lose' 'my' 'faith' 'in' 'films' 'of' 'recent'\n",
      " 'being' 'inundated' 'with' 'the' 'typical' 'genre' 'hollywood' 'film'\n",
      " 'story' 'lines' 'fail' 'and' 'camera' 'work' 'is' 'merely' 'copied'\n",
      " 'from' 'the' 'last' 'film' 'of' 'similiar' 'taste' 'but' 'then' 'i' 'saw'\n",
      " 'zentropa' 'europa' 'and' 'my' 'faith' 'was' 'renewed' 'not' 'only' 'is'\n",
      " 'the' 'metaphorical' 'storyline' 'enthralling' 'but' 'the' 'use' 'of'\n",
      " 'color' 'and' 'black' 'and' 'white' 'is' 'visually' 'stimulating' 'the'\n",
      " 'narrator' 'max' 'von' 'sydow' 'takes' 'you' 'through' 'a'\n",
      " 'spellbounding' 'journey' 'every' 'step' 'of' 'the' 'way' 'and'\n",
      " 'engrosses' 'you' 'into' 'europa' '1945' 'we' 'have' 'all' 'seen' 'death'\n",
      " 'put' 'on' 'screen' 'in' 'a' 'hundred' 'thousand' 'ways' 'but' 'the'\n",
      " 'beauty' 'of' 'this' 'film' 'is' 'how' 'it' 'takes' 'you' 'through'\n",
      " 'every' 'slowmoving' 'moment' 'that' 'leads' 'you' 'to' 'death' 'unlike'\n",
      " 'many' 'films' 'it' 'doesnt' 'cut' 'after' 'one' 'second' 'of' 'showing'\n",
      " 'for' 'example' 'a' 'knife' 'but' 'forces' 'you' 'to' 'watch' 'the'\n",
      " 'devastating' 'yet' 'sensuous' 'beauty' 'of' 'a' 'mans' 'final' 'moments'\n",
      " 'i' 'think' 'we' 'can' 'all' 'take' 'something' 'different' 'away' 'from'\n",
      " 'what' 'this' 'movie' 'is' 'trying' 'to' 'say' 'but' 'it' 'is'\n",
      " 'definitely' 'worth' 'taking' 'the' 'time' 'to' 'find' 'out' 'what' 'it'\n",
      " 'all' 'really' 'means' 'i' 'would' 'love' 'to' 'talk' 'more' 'in' 'depth'\n",
      " 'about' 'the' 'film' 'for' 'any' 'one' 'who' 'wishes' 'to' 'send' 'me'\n",
      " 'an' 'email' 'enjoy' \"it'\"]\n",
      "Label: [1]\n",
      "Sample 6:\n",
      "Text: [\"b'critics\" 'need' 'to' 'review' 'what' 'they' 'class' 'as' 'a' 'quality'\n",
      " 'movie' 'i' 'think' 'the' 'critics' 'have' 'seen' 'too' 'many' 'actions'\n",
      " 'films' 'and' 'have' 'succumbed' 'to' 'the' 'matrix' 'style' 'of' 'films'\n",
      " 'europa' 'is' 'a' 'breath' 'of' 'fresh' 'air' 'a' 'film' 'with' 'so'\n",
      " 'many' 'layers' 'that' 'one' 'viewing' 'is' 'not' 'enough' 'to'\n",
      " 'understand' 'or' 'appreciate' 'this' 'outstanding' 'film' 'lars' 'von'\n",
      " 'trier' 'shows' 'that' 'old' 'styles' 'of' 'filming' 'can' 'produce'\n",
      " 'marvellous' 'cinema' 'and' 'build' 'drama' 'and' 'tension' 'the' 'back'\n",
      " 'projection' 'effect' 'he' 'uses' 'during' 'the' 'film' 'arouses' 'and'\n",
      " 'enhances' 'the' 'characters' 'and' 'the' 'focus' 'of' 'the'\n",
      " 'conversation' 'they' 'are' 'having' 'other' 'effects' 'he' 'uses' 'such'\n",
      " 'as' 'the' 'colour' 'and' 'black' 'and' 'white' 'in' 'one' 'scene' 'much'\n",
      " 'like' 'hitchcock' 'and' 'the' 'girl' 'with' 'the' 'red' 'coat' 'grabs'\n",
      " 'attention' 'and' 'enhances' 'the' 'drama' 'and' 'meaning' 'of' 'the'\n",
      " 'scene' 'the' 'commentary' 'is' 'superb' 'and' 'has' 'a' 'hypnotic'\n",
      " 'effect' 'again' 'maintaining' 'the' 'focus' 'on' 'the' 'central'\n",
      " 'characters' 'in' 'the' 'scene' 'and' 'there' 'actionsbr' 'br' 'i'\n",
      " 'could' 'talk' 'about' 'the' 'effects' 'more' 'but' 'i' 'think' 'you'\n",
      " 'all' 'would' 'agree' 'they' 'push' 'this' 'film' 'into' 'a' 'category'\n",
      " 'of' 'its' 'own' 'and' 'really' 'heighten' 'the' 'drama' 'of' 'the'\n",
      " 'film' 'a' 'film' 'to' 'buy' 'if' 'you' 'dont' 'own' 'already' 'and'\n",
      " 'one' 'to' 'see' 'if' 'you' 'have' 'notbr' 'br' '1010' 'dont' 'miss'\n",
      " 'this' 'artistic' 'noir' 'film' 'from' 'one' 'of' 'the' 'great' 'film'\n",
      " \"directors'\"]\n",
      "Label: [1]\n",
      "Sample 7:\n",
      "Text: [\"b'it\" 'is' 'not' 'every' 'films' 'job' 'to' 'stimulate' 'you'\n",
      " 'superficially' 'i' 'will' 'take' 'an' 'ambitious' 'failure' 'over' 'a'\n",
      " 'massmarket' 'hit' 'any' 'day' 'while' 'this' 'really' 'cant' 'be'\n",
      " 'described' 'as' 'a' 'failure' 'the' 'sum' 'of' 'its' 'parts' 'remains'\n",
      " 'ambiguous' 'that' 'indecipherable' 'quality' 'tantalizes' 'me' 'into'\n",
      " 'watching' 'it' 'again' 'and' 'again' 'this' 'is' 'a' 'challenging'\n",
      " 'provocative' 'movie' 'that' 'does' 'not' 'wrap' 'things' 'up' 'neatly'\n",
      " 'the' 'problem' 'with' 'the' 'movie' 'is' 'in' 'its' 'structure' 'its'\n",
      " 'inpenetrable' 'plot' 'seems' 'to' 'be' 'winding' 'up' 'just' 'as' 'a'\n",
      " 'second' 'ending' 'is' 'tacked' 'on' 'though' 'everything' 'is'\n",
      " 'technically' 'dazzling' 'the' 'movie' 'is' 'exactly' 'too' 'long' 'by'\n",
      " 'that' 'unit' 'the' 'longdelayed' 'climax' 'of' 'leos' 'awakening'\n",
      " 'comes' 'about' '20' 'minutes' 'latebr' 'br' 'great' 'cinematography'\n",
      " 'often' 'comes' 'at' 'the' 'expense' 'of' 'a' 'decent' 'script' 'but'\n",
      " 'here' 'the' 'innovative' 'camera' 'technique' 'offers' 'a' 'wealth' 'of'\n",
      " 'visual' 'ideas' 'the' 'compositing' 'artifice' 'is' 'provocative' 'and'\n",
      " 'engaging' 'a' 'character' 'is' 'rearprojected' 'but' 'his' 'own' 'hand'\n",
      " 'in' 'the' 'foreground' 'isnt' 'the' 'world' 'depicted' 'is' 'deliberate'\n",
      " 'treacherous' 'and' 'absurd' 'keep' 'your' 'eyes' 'peeled' 'for' 'a'\n",
      " 'memorable' 'technically' 'astonishing' 'assassination' 'that' 'will'\n",
      " 'make' 'your' 'jaw' 'dropbr' 'br' 'the' 'compositions' 'are' 'stunning'\n",
      " 'whomever' 'chose' 'to' 'release' 'the' 'out' 'of' 'print' 'videotape'\n",
      " 'in' 'the' 'pan' 'scan' 'format' 'must' 'have' 'never' 'seen' 'it'\n",
      " 'where' 'is' 'the' 'dvdbr' 'br' 'it' 'is' 'unfathomable' 'how' 'anyone'\n",
      " 'could' 'give' 'this' 'much' 'originality' 'a' 'bad' 'review' 'you'\n",
      " 'should' 'see' 'it' 'at' 'least' 'once' 'you' 'get' 'the' 'sense' 'that'\n",
      " 'von' 'trier' 'bit' 'off' 'more' 'than' 'he' 'could' 'chew' 'but' 'this'\n",
      " 'movie' 'ends' 'up' 'being' 'richer' 'for' 'it' 'i' 'suspect' 'he' 'is'\n",
      " 'familiar' 'with' 'hitchcocks' 'foreign' 'correspondent' 'in' 'which'\n",
      " 'devious' 'europeans' 'also' 'manipulate' 'an' 'american' 'dupe' 'and'\n",
      " 'several' 'welles' 'movies' 'that' 'take' 'delirious' 'joy' 'in'\n",
      " 'technique' 'as' 'much' 'as' 'he' 'does' 'all' 'von' 'trier' 'movies'\n",
      " 'explore' 'the' 'plight' 'of' 'the' 'naif' 'amidst' 'unforgiving'\n",
      " 'societies' 'after' 'zentropa' 'von' 'trier' 'moved' 'away' 'from' 'this'\n",
      " 'type' 'of' 'audacious' 'technical' 'experiment' 'towards' 'dreary'\n",
      " 'overrated' 'unnuanced' 'sap' 'like' 'breaking' 'the' 'waves' 'and'\n",
      " 'dancer' 'in' 'the' \"dark'\"]\n",
      "Label: [1]\n",
      "Sample 8:\n",
      "Text: [\"b'the\" 'best' 'way' 'for' 'me' 'to' 'describe' 'europa' 'which' 'is'\n",
      " 'high' 'on' 'the' 'list' 'of' 'my' 'favourite' 'films' 'is' 'the'\n",
      " 'exclamation' 'that' 'came' 'from' 'a' 'companion' 'after' 'the' 'film'\n",
      " 'ended' 'i' 'didnt' 'know' 'films' 'could' 'be' 'made' 'like' 'that'\n",
      " 'entirely' 'original' 'in' 'its' 'visual' 'style' 'it' 'is' 'one' 'of'\n",
      " 'the' 'best' 'examples' 'of' 'what' 'cinema' 'can' 'be' 'its' 'as' 'far'\n",
      " 'away' 'from' 'the' 'master' 'and' 'coverage' 'style' 'of' 'shooting'\n",
      " 'as' 'one' 'can' 'get' 'perfectly' 'integrating' 'many' 'layers' 'of'\n",
      " 'image' 'sound' 'effects' 'props' 'dialogue' 'voice' 'over' 'performance'\n",
      " 'editing' 'lighting' 'etc' 'all' 'equal' 'none' 'predominant' 'despite'\n",
      " 'hollywoods' 'dialogue' 'myopia' 'cinema' 'is' 'not' 'about' 'dialogue'\n",
      " 'nor' 'is' 'it' 'about' 'beautiful' 'lighting' 'action' 'or' 'music' 'it'\n",
      " 'works' 'best' 'when' 'all' 'the' 'elements' 'are' 'on' 'an' 'equal'\n",
      " 'footing' 'where' 'only' 'the' 'blending' 'of' 'those' 'elements' 'in'\n",
      " 'the' 'order' 'or' 'combination' 'in' 'which' 'they' 'are' 'presented'\n",
      " 'will' 'communicate' 'the' 'idea' 'reduce' 'or' 'eliminate' 'the'\n",
      " 'contribution' 'of' 'one' 'element' 'and' 'the' 'film' 'has' 'no'\n",
      " 'meaning' 'europa' 'is' 'what' 'cinema' 'should' 'strive' 'to' \"be'\"]\n",
      "Label: [1]\n",
      "Sample 9:\n",
      "Text: [\"b'released\" 'as' 'zentropa' 'in' 'north' 'america' 'to' 'avoid'\n",
      " 'confusion' 'with' 'agniezska' 'hollands' 'own' 'holocaust' 'film'\n",
      " 'europa' 'europa' 'this' 'third' 'theatrical' 'feature' 'by' 'a'\n",
      " 'filmmaker' 'who' 'never' 'ceases' 'to' 'surprise' 'inspire' 'or'\n",
      " 'downright' 'shock' 'is' 'a' 'bizarre' 'nostalgic' 'elaborate' 'film'\n",
      " 'about' 'a' 'naive' 'american' 'in' 'germany' 'shortly' 'following' 'the'\n",
      " 'end' 'of' 'wwii' 'the' 'american' 'named' 'leo' 'doesnt' 'fully' 'get'\n",
      " 'what' 'hes' 'doing' 'there' 'he' 'has' 'come' 'to' 'take' 'part' 'in'\n",
      " 'fixing' 'up' 'the' 'country' 'since' 'in' 'his' 'mind' 'its' 'about'\n",
      " 'time' 'germany' 'was' 'shown' 'some' 'charity' 'no' 'matter' 'how'\n",
      " 'that' 'sounds' 'he' 'is' 'not' 'a' 'nazi' 'sympathizer' 'or' 'so' 'much'\n",
      " 'as' 'especially' 'progerman' 'merely' 'mixed' 'up' 'his' 'uncle' 'who'\n",
      " 'works' 'on' 'the' 'railroad' 'gets' 'leo' 'a' 'job' 'as' 'a' 'helmsman'\n",
      " 'on' 'a' 'sleeping' 'car' 'and' 'he' 'is' 'increasingly' 'enmeshed' 'in'\n",
      " 'a' 'vortex' 'of' '1945' 'germanys' 'horrors' 'and' 'enigmasbr' 'br'\n",
      " 'this' 'progression' 'starts' 'when' 'leo' 'played' 'rather' 'memorably'\n",
      " 'by' 'the' 'calm' 'yet' 'restless' 'actor' 'jeanmarc' 'barr' 'meets' 'a'\n",
      " 'sultry' 'heiress' 'on' 'the' 'train' 'played' 'by' 'barbara' 'sukowa'\n",
      " 'an' 'actress' 'with' 'gentility' 'on' 'the' 'surface' 'but' 'internal'\n",
      " 'vigor' 'she' 'seduces' 'him' 'and' 'then' 'takes' 'him' 'home' 'to'\n",
      " 'meet' 'her' 'family' 'which' 'owns' 'the' 'company' 'which'\n",
      " 'manufactures' 'the' 'trains' 'these' 'were' 'the' 'precise' 'trains'\n",
      " 'that' 'took' 'jews' 'to' 'their' 'deaths' 'during' 'the' 'war' 'but'\n",
      " 'now' 'they' 'run' 'a' 'drab' 'daytoday' 'timetable' 'and' 'the' 'womans'\n",
      " 'uncle' 'kessler' 'postures' 'as' 'another' 'one' 'of' 'those' 'good'\n",
      " 'germans' 'who' 'were' 'just' 'doing' 'their' 'jobs' 'there' 'is' 'also'\n",
      " 'udo' 'kier' 'the' 'tremendous' 'actor' 'who' 'blew' 'me' 'away' 'in'\n",
      " 'von' 'triers' 'shocking' 'second' 'film' 'epidemic' 'though' 'here' 'he'\n",
      " 'is' 'mere' 'scenerybr' 'br' 'another' 'guest' 'at' 'the' 'house' 'is'\n",
      " 'eddie' 'constantine' 'an' 'actor' 'with' 'a' 'quiet' 'strength'\n",
      " 'playing' 'a' 'somber' 'american' 'intelligence' 'man' 'he' 'can'\n",
      " 'confirm' 'that' 'uncle' 'kessler' 'was' 'a' 'war' 'criminal' 'though'\n",
      " 'it' 'is' 'all' 'completely' 'baffling' 'to' 'leo' 'americans' 'have'\n",
      " 'been' 'characterized' 'as' 'gullible' 'rubes' 'out' 'of' 'their'\n",
      " 'element' 'for' 'decades' 'but' 'little' 'have' 'they' 'been' 'more'\n",
      " 'blithely' 'unconcerned' 'than' 'leo' 'who' 'goes' 'back' 'to' 'his'\n",
      " 'job' 'on' 'what' 'gradually' 'looks' 'like' 'his' 'own' 'customized'\n",
      " 'death' 'trainbr' 'br' 'the' 'story' 'is' 'told' 'in' 'a' 'purposely'\n",
      " 'uncoordinated' 'manner' 'by' 'the' 'films' 'danish' 'director' 'lars'\n",
      " 'von' 'trier' 'whose' 'anchor' 'is' 'in' 'the' 'films' 'breathtaking'\n",
      " 'editing' 'and' 'cinematography' 'he' 'shoots' 'in' 'black' 'and' 'white'\n",
      " 'and' 'color' 'he' 'uses' 'doubleexposures' 'optical' 'effects' 'and'\n",
      " 'trick' 'photography' 'having' 'actors' 'interact' 'with' 'rearprojected'\n",
      " 'footage' 'he' 'places' 'his' 'characters' 'inside' 'a' 'richly' 'shaded'\n",
      " 'visceral' 'world' 'so' 'that' 'they' 'sometimes' 'feel' 'like' 'insects'\n",
      " 'caught' 'between' 'glass' 'for' 'our' 'more' 'precise' 'surveybr' 'br'\n",
      " 'this' 'grand' 'jury' 'prizewinning' 'surrealist' 'work' 'is'\n",
      " 'allegorical' 'but' 'maybe' 'in' 'a' 'distinct' 'tone' 'for' 'every'\n",
      " 'viewer' 'i' 'interpret' 'it' 'as' 'a' 'film' 'about' 'the' 'last' 'legs'\n",
      " 'of' 'nazism' 'symbolized' 'by' 'the' 'train' 'and' 'the' 'ethical'\n",
      " 'accountability' 'of' 'americans' 'and' 'others' 'who' 'appeared' 'too'\n",
      " 'late' 'to' 'salvage' 'the' 'martyrs' 'of' 'these' 'trains' 'and' 'the'\n",
      " 'camps' 'where' 'they' 'distributed' 'their' 'condemned' 'shiploads'\n",
      " 'during' 'the' 'time' 'frame' 'of' 'the' 'movie' 'and' 'the' 'nazi'\n",
      " 'state' 'and' 'such' 'significance' 'to' 'the' 'train' 'are' 'dead' 'but'\n",
      " 'like' 'decapitated' 'chickens' 'they' 'persist' 'in' 'jolting' 'through'\n",
      " 'their' 'reflexesbr' 'br' 'the' 'characters' 'music' 'dialogue' 'and'\n",
      " 'plot' 'are' 'deliberately' 'hammy' 'and' 'almost' 'satirically'\n",
      " 'procured' 'from' 'film' 'noir' 'conventions' 'the' 'most' 'entrancing'\n",
      " 'points' 'in' 'the' 'movie' 'are' 'the' 'entirely' 'cinematographic'\n",
      " 'ones' 'two' 'trains' 'halting' 'back' 'and' 'forth' 'barr' 'on' 'one'\n",
      " 'and' 'sukowa' 'on' 'another' 'an' 'underwater' 'shot' 'of'\n",
      " 'proliferating' 'blood' 'an' 'uncommonly' 'expressive' 'sequence' 'on'\n",
      " 'what' 'it' 'must' 'be' 'like' 'to' 'drown' 'and' 'most' 'metaphysically'\n",
      " 'affecting' 'of' 'all' 'an' 'anesthetic' 'shot' 'of' 'train' 'tracks'\n",
      " 'as' 'max' 'von' 'sydows' 'voice' 'allures' 'us' 'to' 'hark' 'back' 'to'\n",
      " 'europe' 'with' 'him' 'and' 'abandon' 'our' 'personal' \"restraint'\"]\n",
      "Label: [1]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(imdb_train):\n",
    "    text, label = data  # if data is a list with 2 elements: text and label\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    if i == 9:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fb459ef-177f-4edc-a8f4-10fb492a7aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train = imdb_train.map(operations=[lookup_op, pad_op], input_columns=['text'])\n",
    "imdb_train = imdb_train.map(operations=[type_cast_op], input_columns=['label'])\n",
    "\n",
    "imdb_test = imdb_test.map(operations=[lookup_op, pad_op], input_columns=['text'])\n",
    "imdb_test = imdb_test.map(operations=[type_cast_op], input_columns=['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32df41f3-c755-4471-9ce7-e55bb1f2a9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "Text: [400000     31    181      6    861     17      0    245    300    170\n",
      " 400000    319    208    244      0   7860      3   9752    525    117\n",
      " 154351     63     14    181  24065   3534    161     63     14     29\n",
      "   4114    140     38   1666  10809    791     17      7    787     18\n",
      " 136283    588   1906      5    507 110195     14     64      0     56\n",
      "   4517      6   3313     17      0 400000  30410     34   9849     33\n",
      "      4    203     12      0    245    300     31      7     56 400000\n",
      "  13303 223958     14      7   1594  42131      6     37   1983   1472\n",
      "     37     14  15493     20     14   1923     19      7 400000      5\n",
      "    433     20    317  17428     54  22209      0   1261  30410  30410\n",
      "     37   1005     14 109159 400000      6     56     73     48   1380\n",
      "     48    332   3109      0   1662  11835   8973     34  12792      5\n",
      " 400000 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001]\n",
      "Label: [1.]\n",
      "Sample 1:\n",
      "Text: [400000     14      0     96    929   1005  79289    541      6     82\n",
      "     83     81    117   3006  32330     12     32   4749     21    319\n",
      "  15215    127     37     14    120      0    248   8117     10     64\n",
      "      3    155   2290    740  32294  36335      0   7161    158    249\n",
      "   4145 266325 398956    117   2923      0   4977     33   5042     56\n",
      "  11383     34     37     14    588     26    254    161     20     14\n",
      "  21393    296    134  27710      5   1728      0   2615   3398      3\n",
      "  17495      5   2237   6202     47    317    978     18    847  20998\n",
      "   4734     35      0   2686      3      0    581     47    605      4\n",
      "    203     38   3607    103    420     25      0   1135     18   9313\n",
      "    187     34     47 400000    866     12     18    388     75     26\n",
      "   2267  10340  28568   2191 400000 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001]\n",
      "Label: [1.]\n",
      "Sample 2:\n",
      "Text: [400000   4145  27785     14    332  10256      6    595     66     50\n",
      "   4276     77      3    101     32    191    929    110    423     32\n",
      "    254 400000  30410     18  11987   9752    509     19      7  39120\n",
      "   1470   3930     17    100    109   1183   4739      6   7401   8065\n",
      "  16824      7    461    140      3    514   6556   3866  10938      4\n",
      "    275      6     44   5258     20     14     36      7   2147   2170\n",
      "     19     18   1177   3380 400000  30410     26   5152   3380    103\n",
      "      7    664     19      7    364   8475     13      0 223958   1609\n",
      "    331     26    664     14      4   2055      4      0   1075      3\n",
      "      0   1892     61      0   5127     32  14736      7  18085    799\n",
      "     14    116     13      0  27011      7   5510   4019  36220     61\n",
      "      7   1892   5127     32     36  31637    504      0    853     39\n",
      "     33     51  14736     63     32    109  33096      4      0    514\n",
      "  39926      3  18737      4    125   8979 400000  30410      0   1609\n",
      "   3930     14    117     29  34373   3102  15159  10752    131    214\n",
      "     17     64     47   3870      5  41820      6     48   5707   8065\n",
      "  44369    131      0    137  19074      4   6314    101   2703     17\n",
      " 400000   1741   4951      4     33    120   4328     25  13916    158\n",
      "   3063  10230     19     39     32     32  23582     19      6      7\n",
      "   2895    236     17     47    261   5510   1433    553 400000  30410\n",
      "     22      7    515    175 400000   8065  11070     25      0   1470\n",
      "     17      7  86499   1211      6   1139      3    109  18545     18\n",
      "   9578      0   1211      4      0  22456      3      7  12846     18\n",
      "   2824      4     26   7740      5    907      7   2540      4      7\n",
      "     79   4974    168     18  11070     25      0   1470     22    152\n",
      "   1512      5   2345      6      0   3451   4614     13      7    620\n",
      "    231    862     22      0   1569   1069     18   6038     12     26\n",
      "    664     14      4   1190      5     36   4526   3114     19     18\n",
      "   3109      0   1470   6865      7   1752   1641     18    976     22\n",
      "  40157   1512      4    534      0   1470      5    837      0   4974\n",
      "     83     81    757      4  36483      0    794     20     14      7\n",
      "   2215   3173   2170   1689  10435      6    853     20     94     91\n",
      "   1927      6      7 400000  30410     47   5186    197     48   8929\n",
      "    333   1125    125     19      7   2307      3   6310   5662     13\n",
      "  18630      5  23155    420     17      0  33690      3      0 400000\n",
      "  30410    504      0    853     12     37    319     14   1799   8974\n",
      "     41   5750  15525   4145 266325    168   1588   2923      0   4977\n",
      "      5      0  36381      0   1211   1500    979   1069    588    339\n",
      "    285    138   1472  14663      7 400000 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001]\n",
      "Label: [1.]\n",
      "Sample 3:\n",
      "Text: [400000  51000    445      4    285    518      4   4466     77    319\n",
      "   4276    100   1465     22    392    261 400000  30410     41   4146\n",
      "     37    319      0    234      3 129528      6     77      3      0\n",
      "   3468    907     20   1914    117     29    167   7852    326      4\n",
      "    214     41     52   3978      0  11875      3     69     13      7\n",
      "    137   2491     10   3233      6     48   1500  16464    971     26\n",
      "    702      5     67     14   5254    561    103    871     73      6\n",
      "      7   3682   2288   2491     71    621     14   1324      6      0\n",
      "    137      5  86262     14      6      0 400000  30410     48      3\n",
      "      0    254   2054      3     37     14     61      0    461   2122\n",
      "   1916      0 400000     13      0   1470      7   1500    635      6\n",
      "     29    591    209  10500   1135     17  12662    383   6044     20\n",
      "   8278    285      3  19768  69894     12   3603   4190   1135   8923\n",
      "     17      0  10065      3    639      4  11191   2474      3   5988\n",
      "    296    181   2182    215     17      0   1500     61  54938   3380\n",
      "     71    629    767      6      0 400000     86     91    253      0\n",
      "    639    430     13      0    437     20     14     48      3      0\n",
      "    654     41    835     59   4145  27785     26  30368      3   5988\n",
      "     42   2441     60    433     20     64      0     56 400000  30410\n",
      "      0    234      3   2829      6      0    319     15   3006    117\n",
      "     61  86262   1395     14   2643     21      0   1388  35701     41\n",
      "     33    332    541   1096    117     12      6      7 400000  30410\n",
      "      0    234      3    521   2841      6     37    319     15    143\n",
      "    751 400000 400000     14    353     19  86262   5152     20   3998\n",
      "     60      0  52185     41    405     25     26    542      6      0\n",
      "   1859 400000     37   6202    907      0  70172      3  12413  28612\n",
      " 400000      3   1470  21404     98      0   5510   9429      3  72574\n",
      "      5     64      0   5174   3337      4    190     20  12910    285\n",
      "      3 400000      6      0    179      0    726   5808     14    595\n",
      "      4   2188      7  24209     22      0    156      3    153     48\n",
      "     61   1174     14    222   5578     20    970     12     77     69\n",
      "     32   4702  25342      4      0   9956    654   4841    204    101\n",
      "    553     77     69    117   8065     32  13830      6     34     88\n",
      "    936   1335     59 400000  30410      0   1713     74    751  39652\n",
      "    143     21   5123   4145  79647     14  18068    317     20   6303\n",
      "     81     75      0    523      5    907     81   3106     75  86262\n",
      "    362     42     22    246     14      7  10212    241      4 400000\n",
      "  30410      0   1005   3998     60      0    389     12     48     14\n",
      "      7  18301     83     39  46768   3008      7    437     41    253\n",
      "      0    215   1159    180      6   8747      6      0   2237    111\n",
      " 400000   1395 136283   2199     60     10   2938      5   2441     60\n",
      "    134     71    261   2695   1403     22     48     79   4145  27785\n",
      "   1706 400000      4    285     21    433   2923      0   4977      5\n",
      "   8747     34    114     41    346     26   2323   2153  46768   6769\n",
      "    143    900     41    238   3261     22      0    215    241    105\n",
      "      0    156      3   8747     61     81   2516    303      0    444\n",
      "   1395      4  18586     44   1970     34      3    746     39    332\n",
      " 400000 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001\n",
      " 400001 400001 400001 400001 400001 400001 400001 400001 400001 400001]\n",
      "Label: [1.]\n",
      "Sample 4:\n",
      "Text: [400000     15      0     58    873     12  22118      4   1676     19\n",
      "     41   3136      0   2319   5072      4  14705    159     63     15\n",
      "    531      0   2491    332      6    192   1452    214     33     41\n",
      "    541      7    319      3    125   2026   9780      0  29591      3\n",
      "  14705     32    100   4571     12    130    319     41   1716      6\n",
      "     47   3050     43     91   7642      6   5459   4458    392    785\n",
      "   1255  21419   1893  11896   2290  22181  14705     31     56  35234\n",
      "   4282     73   1096    155     55     94  35109     60      6      7\n",
      "     93     82    114   9849     30      0     58      4  11895  15525\n",
      "   4145  27785      7   9780    120    138      0    137      3     26\n",
      "   1588   2923      0   4977      5   8747      6      0   2237     34\n",
      "     37     14   8979      0    853     12  14705     31   1527  19552\n",
      "     21    319   1232     10    100    173     14      7   1340     98\n",
      "   5992   7023  41524  21168    117  34635   3566   4555   7394      5\n",
      "    214     14   3366   2431     60     22      0   1670   1542     34\n",
      "    102     88      0    346  14705     31     51   4555    420   7844\n",
      "    683    974   1932      5    207    744    130    297    816   4534\n",
      "  30410  30410      0  29591      6  14705     32     36   6917  26053\n",
      "     47     36      7    305      3   1135     74   5732     47     56\n",
      "      7    305      3   5732  35917   1135    181    117     26     58\n",
      "    319      0   4736      3   1340   4145  27785   2054      0   5251\n",
      "      3      0    444   1395      4   1707     95     75     26     85\n",
      "      5    181    117   4736      0    319   2276     17      0    444\n",
      "   1395     46      6      0    305      3  14705     53      0   2052\n",
      "    134  71309     19     53    483    135      0   2477      0   1713\n",
      "      3      0  12684   5123   4145  79647   4382     95    135     75\n",
      "      7   1479   4294    207     53  16856      6  14705     37   2415\n",
      "   4145  27785      5     26     87  63512      4    642     17      0\n",
      "   8085      3     79      5  12779     63     32    109   3468      6\n",
      "  14705     61      7   1395      6      0   2093     38     14      6\n",
      "    521      5    298     43  12574     17      7    899      6      0\n",
      "  37038     38     43     30   8237   4145  27785     14    595      4\n",
      "    273     95    197    181  22801      0  17172   6779     46    899\n",
      "     31     74      0   2219     10   3233     47     84   2661     12\n",
      "      0     58    635      3  16464  16824 400000  15336     14      6\n",
      "   8237    108     18     14      0     91   1395 124004   1970     33\n",
      "  17070     74      0    319  30410  30410      0   3171     32    219\n",
      "     39    107     36     30     13   4387     17   3171      6    168\n",
      "   4145  27785   1588     34  86908    120    113      0   3063     32\n",
      "   1071    100  27710     12     81  46768    588   2065     60     13\n",
      "    101      0     58     79    469     34     41     54    117      4\n",
      "    389     66      0   7872    883      3 400000  15336      6      0\n",
      "    410    542    507   5651  27113     14   3892   7019    135     21\n",
      "      0     55   6047   1051    207     18  27543      6      0   1588\n",
      "    294    743    378  34079    117      0   4736      3   1340      0\n",
      "    319   2441     17    162   3644   2282      4   3050     60     25\n",
      "     26   8836     92    218      6     37   5510    241     17     91\n",
      "      0   2265  22531      3   4145  79647      4   5874     26   3871\n",
      "  14705     14      7   5977    319      5     41  52717    275   2412\n",
      "    102      7   8287     12   4145  27785     31   3183     37    179]\n",
      "Label: [1.]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(imdb_train):\n",
    "    text, label = data  # if data is a list with 2 elements: text and label\n",
    "    print(f\"Sample {i}:\")\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Label: {label}\")\n",
    "    if i == 4:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e61b19dc-1481-4a32-86fe-8fe4fcb6f098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train, imdb_valid = imdb_train.split([0.7, 0.3])\n",
    "len(imdb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "148fa3e5-5018-4601-a7c7-d6562bb1f5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imdb_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe7fd692-c42b-47a2-8be9-ca7955c629f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train = imdb_train.batch(64, drop_remainder=True)\n",
    "imdb_valid = imdb_valid.batch(64, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94338dda-1d06-44f8-bbb5-35d354180faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import Tensor, nn, ops\n",
    "from mindspore.common.initializer import Normal\n",
    "\n",
    "class CNN(nn.Cell):\n",
    "    def __init__(self, embeddings, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        #super(CNN, self).__init__()\n",
    "        #self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        super().__init__()\n",
    "        vocab_size, embedding_dim = embeddings.shape\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, embedding_table=ms.Tensor(embeddings), padding_idx=pad_idx)\n",
    "\n",
    "        self.convs = nn.CellList([\n",
    "            nn.Conv2d(1, n_filters, (fs, embedding_dim), pad_mode = 'valid', has_bias=True) for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Dense(len(filter_sizes) * n_filters, output_dim, has_bias=True, weight_init=Normal(0.02))\n",
    "        \n",
    "        self.dropout = nn.Dropout(1 - dropout)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        #self.reshape = nn.Reshape()\n",
    "        self.cat = ops.Concat(axis=1)\n",
    "\n",
    "    def construct(self, text):\n",
    "        # embedded = [batch size, 1, sent len, emb dim]\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        squeeze = ops.Squeeze(3)\n",
    "\n",
    "        conved = [squeeze(self.relu(conv(embedded))) for conv in self.convs]\n",
    "\n",
    "        \n",
    "        squeeze = ops.Squeeze(2)\n",
    "        #max_pool = nn.MaxPool1d(kernel_size=None)\n",
    "        pooled = [squeeze(nn.MaxPool1d(kernel_size=conv.shape[2])(conv)) for conv in conved]\n",
    "        \n",
    "\n",
    "        # cat = [batch size, n_filters * len(filter_sizes)]\n",
    "        cat = self.dropout(self.cat(tuple(pooled)))\n",
    "\n",
    "        return self.fc(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d94d1e9-e944-45b8-bacf-f8631aec51e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2376:140691561178304,MainProcess):2023-07-07-23:54:49.538.181 [mindspore/nn/layer/basic.py:167] For Dropout, this parameter `keep_prob` will be deprecated, please use `p` instead.\n"
     ]
    }
   ],
   "source": [
    "#INPUT_DIM = len(TEXT.vocab)\n",
    "#EMBEDDING_DIM = 100\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "#PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "lr = 0.001\n",
    "PAD_IDX = vocab.tokens_to_ids('<pad>')\n",
    "\n",
    "model = CNN(embeddings, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "710d7c8d-f2de-4c58-acb3-07c8f6daaf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_fn(data, label):\n",
    "    logits = model(data)\n",
    "    loss = loss_fn(logits, label)\n",
    "    return loss\n",
    "\n",
    "grad_fn = ms.value_and_grad(forward_fn, None, optimizer.parameters)\n",
    "\n",
    "def train_step(data, label):\n",
    "    loss, grads = grad_fn(data, label)\n",
    "    optimizer(grads)\n",
    "    return loss\n",
    "\n",
    "def train_one_epoch(model, train_dataset, epoch=0):\n",
    "    model.set_train()\n",
    "    total = train_dataset.get_dataset_size()\n",
    "    loss_total = 0\n",
    "    step_total = 0\n",
    "    with tqdm(total=total) as t:\n",
    "        t.set_description('Epoch %i' % epoch)\n",
    "        for i in train_dataset.create_tuple_iterator():\n",
    "            loss = train_step(*i)\n",
    "            loss_total += loss.asnumpy()\n",
    "            step_total += 1\n",
    "            t.set_postfix(loss=loss_total/step_total)\n",
    "            t.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2c96d40-9219-48c3-97da-029ea4828300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of each batch.\n",
    "    \"\"\"\n",
    "    # Round off the predicted value.\n",
    "    rounded_preds = np.around(ops.sigmoid(preds).asnumpy())\n",
    "    correct = (rounded_preds == y).astype(np.float32)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b460fb64-3759-459c-8336-0903cdaa1404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset, criterion, epoch=0):\n",
    "    total = test_dataset.get_dataset_size()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    step_total = 0\n",
    "    model.set_train(False)\n",
    "\n",
    "    with tqdm(total=total) as t:\n",
    "        t.set_description('Epoch %i' % epoch)\n",
    "        for i in test_dataset.create_tuple_iterator():\n",
    "            predictions = model(i[0])\n",
    "            loss = criterion(predictions, i[1])\n",
    "            epoch_loss += loss.asnumpy()\n",
    "\n",
    "            acc = binary_accuracy(predictions, i[1])\n",
    "            epoch_acc += acc\n",
    "\n",
    "            step_total += 1\n",
    "            t.set_postfix(loss=epoch_loss/step_total, acc=epoch_acc/step_total)\n",
    "            t.update(1)\n",
    "\n",
    "    return epoch_loss / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "970d1a9c-abe4-44ad-b5c4-fa561f9f8af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 273/273 [00:12<00:00, 21.72it/s, loss=0.455]\n",
      "Epoch 0: 100%|| 117/117 [00:08<00:00, 13.64it/s, acc=0.857, loss=0.339]\n",
      "Epoch 1: 100%|| 273/273 [00:09<00:00, 29.13it/s, loss=0.32] \n",
      "Epoch 1: 100%|| 117/117 [00:08<00:00, 13.92it/s, acc=0.895, loss=0.267]\n",
      "Epoch 2: 100%|| 273/273 [00:09<00:00, 29.89it/s, loss=0.256]\n",
      "Epoch 2: 100%|| 117/117 [00:08<00:00, 13.55it/s, acc=0.911, loss=0.227]\n",
      "Epoch 3: 100%|| 273/273 [00:09<00:00, 30.05it/s, loss=0.2]  \n",
      "Epoch 3: 100%|| 117/117 [00:08<00:00, 13.36it/s, acc=0.945, loss=0.158]\n",
      "Epoch 4: 100%|| 273/273 [00:09<00:00, 29.99it/s, loss=0.168]\n",
      "Epoch 4: 100%|| 117/117 [00:08<00:00, 13.75it/s, acc=0.96, loss=0.124] \n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "best_valid_loss = float('inf')\n",
    "ckpt_file_name = os.path.join(cache_dir, 'analysis.ckpt')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, imdb_train, epoch)\n",
    "    valid_loss = evaluate(model, imdb_valid, loss_fn, epoch)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        ms.save_checkpoint(model, ckpt_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93a6a566-7df0-4f93-9109-bada8e80238a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 500) (64, 1)\n"
     ]
    }
   ],
   "source": [
    "for element in imdb_train.take(1):\n",
    "    print(element[0].shape, element[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da5783d6-be1d-42db-90d0-e994c7b3cb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = ms.load_checkpoint(ckpt_file_name)\n",
    "ms.load_param_into_net(model, param_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "348239da-777b-40ba-ae00-e7a068b5b0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|| 391/391 [00:22<00:00, 17.58it/s, acc=0.859, loss=0.342]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34162890688156533"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test = imdb_test.batch(64)\n",
    "evaluate(model, imdb_test, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a06b5391-3ee1-41d1-a32b-f3b19ce99a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence(sentence, max_length, pad_token='<pad>'):\n",
    "    tokenized = sentence.lower().split()\n",
    "    \n",
    "    if len(tokenized) < max_length:\n",
    "        tokenized += [pad_token] * (max_length - len(tokenized))\n",
    "    else:\n",
    "        tokenized = tokenized[:max_length]\n",
    "    \n",
    "    return tokenized\n",
    "\n",
    "score_map = {\n",
    "    1: \"Positive\",\n",
    "    0: \"Negative\"\n",
    "}\n",
    "\n",
    "def predict_sentiment(model, vocab, sentence, max_length=500):\n",
    "    model.set_train(False)\n",
    "    \n",
    "    # Pad sentence\n",
    "    tokenized = pad_sentence(sentence, max_length)\n",
    "    \n",
    "    # Convert tokens to ids\n",
    "    indexed = [vocab.tokens_to_ids(token) for token in tokenized]\n",
    "    \n",
    "    # Create tensor and expand dims\n",
    "    tensor = ms.Tensor(indexed, ms.int32)\n",
    "    tensor = tensor.expand_dims(0)\n",
    "    \n",
    "    # Predict sentiment\n",
    "    prediction = model(tensor)\n",
    "    \n",
    "    # Convert prediction to sentiment\n",
    "    sentiment = score_map[int(np.round(ops.sigmoid(prediction).asnumpy()))]\n",
    "    \n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e9c319b8-32c5-4506-bc27-e5b096be7178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, vocab, \"This film has got to be the epitome of terrible writing and should be a classroom example of 'what not to do' when writing a screenplay. Why would Joshua take on (clearly) amateur writer Adam Gaines script is beyond me. Even his good directing and excellent cinematography could not save this disaster.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "be68bfda-1677-4604-93f0-b7e32af58855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, vocab, \"That's well-paced and not slow and meandering. Good storytelling. Good dialogue that keeps it real.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "65a7d7d9-dd09-4cf4-91c1-1cf239e0132b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, vocab, \"This film is terrible\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aac2ba40-97d7-4fd3-9988-308a1e48077b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, vocab, \"This film is great\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9750a26-0e58-4eff-bd6e-bf65a6fd16b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ecf713-c915-4349-941c-2af46392b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thank you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5cc7d7-05f7-44da-860c-549f8b52fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#thank you!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
